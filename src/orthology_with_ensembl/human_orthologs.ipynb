{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find how many  human gene with low all vs long similarity are orthologs with gene of other species\n",
    "\n",
    "We run pannzer to annotate proeteome as explain in this repo with the genome and annotation (from Ensembl v.104) for :\n",
    "- Human (*Homo sapiens*)\n",
    "- Mouse (*Mus musculus*)\n",
    "- Trout (*Salmo trutta*)\n",
    "- Tilapia (*Oreochromis niloticus*)\n",
    "\n",
    "Then, we compute similarity table with the script `description_table.py`.\n",
    "\n",
    "Then, we ask Ensembl Biomark for orthologeous group with the requests you can find in [`biomart_request.txt`](biomart_request.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_biomart : str = \"human_biomart.txt\"\n",
    "mouse_biomart : str = \"mouse_biomart.txt\"\n",
    "tilapia_biomart : str = \"tilapia_biomart.txt\"\n",
    "trout_biomart : str = \"trout_biomart.txt\"\n",
    "\n",
    "human_similarity : str = \"human.table.similarity.txt\"\n",
    "mouse_similarity : str = \"mouse.table.similarity.txt\"\n",
    "tilapia_similarity : str = \"tilapia.table.similarity.txt\"\n",
    "trout_similarity : str = \"trout.table.similarity.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene2og : dict[str, int] = dict()  # key is a gene id and value is an int, the id of the OG\n",
    "new_group : int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68533 98464 19\n"
     ]
    }
   ],
   "source": [
    "case_new_og = 0\n",
    "case_single_og = 0\n",
    "case_multi_og = 0\n",
    "\n",
    "with open(human_biomart) as biomart:\n",
    "    biomart.readline()\n",
    "    for line in biomart:\n",
    "        line = line.strip().split('\\t')\n",
    "        line = [item for item in line if item != '']\n",
    "        belong_group = set()  # if a gene is already in a OG, add this OG the this set\n",
    "        for id in line:\n",
    "            if id in gene2og:\n",
    "                belong_group.add(gene2og[id])\n",
    "        \n",
    "        if len(belong_group) == 0:  # all geneID are new, we create an OG and add all gene to this OG\n",
    "            case_new_og += 1\n",
    "            og = new_group\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "            new_group += 1\n",
    "\n",
    "        elif len(belong_group) == 1:  # if one or multiple geneID come from an already assign OG, assign other ID to this one\n",
    "            case_single_og += 1\n",
    "            og = list(belong_group)[0]\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "        else:  # if two or more geneID are already assigned to different OG, we arbitrary assign all to one of them and reassign all gene in other OG to the select one\n",
    "            case_multi_og += 1\n",
    "            og = list(belong_group)[0]\n",
    "            belong_group.remove(og)\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "            for k,v in gene2og.items():\n",
    "                if v in belong_group:\n",
    "                    gene2og[k] = og\n",
    "\n",
    "print(case_new_og,case_single_og,case_multi_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35982 107016 6\n"
     ]
    }
   ],
   "source": [
    "case_new_og = 0\n",
    "case_single_og = 0\n",
    "case_multi_og = 0\n",
    "\n",
    "with open(mouse_biomart) as biomart:\n",
    "    biomart.readline()\n",
    "    for line in biomart:\n",
    "        line = line.strip().split('\\t')\n",
    "        line = [item for item in line if item != '']\n",
    "        belong_group = set()  # if a gene is already in a OG, add this OG the this set\n",
    "        for id in line:\n",
    "            if id in gene2og:\n",
    "                belong_group.add(gene2og[id])\n",
    "        \n",
    "        if len(belong_group) == 0:  # all geneID are new, we create an OG and add all gene to this OG\n",
    "            case_new_og += 1\n",
    "            og = new_group\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "            new_group += 1\n",
    "\n",
    "        elif len(belong_group) == 1:  # if one or multiple geneID come from an already assign OG, assign other ID to this one\n",
    "            case_single_og += 1\n",
    "            og = list(belong_group)[0]\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "        else:  # if two or more geneID are already assigned to different OG, we arbitrary assign all to one of them and reassign all gene in other OG to the select one\n",
    "            case_multi_og += 1\n",
    "            og = list(belong_group)[0]\n",
    "            belong_group.remove(og)\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "            for k,v in gene2og.items():\n",
    "                if v in belong_group:\n",
    "                    gene2og[k] = og\n",
    "\n",
    "print(case_new_og,case_single_og,case_multi_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13717 121187 1\n"
     ]
    }
   ],
   "source": [
    "case_new_og = 0\n",
    "case_single_og = 0\n",
    "case_multi_og = 0\n",
    "\n",
    "with open(tilapia_biomart) as biomart:\n",
    "    biomart.readline()\n",
    "    for line in biomart:\n",
    "        line = line.strip().split('\\t')\n",
    "        line = [item for item in line if item != '']\n",
    "        belong_group = set()  # if a gene is already in a OG, add this OG the this set\n",
    "        for id in line:\n",
    "            if id in gene2og:\n",
    "                belong_group.add(gene2og[id])\n",
    "        \n",
    "        if len(belong_group) == 0:  # all geneID are new, we create an OG and add all gene to this OG\n",
    "            case_new_og += 1\n",
    "            og = new_group\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "            new_group += 1\n",
    "\n",
    "        elif len(belong_group) == 1:  # if one or multiple geneID come from an already assign OG, assign other ID to this one\n",
    "            case_single_og += 1\n",
    "            og = list(belong_group)[0]\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "        else:  # if two or more geneID are already assigned to different OG, we arbitrary assign all to one of them and reassign all gene in other OG to the select one\n",
    "            case_multi_og += 1\n",
    "            og = list(belong_group)[0]\n",
    "            belong_group.remove(og)\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "            for k,v in gene2og.items():\n",
    "                if v in belong_group:\n",
    "                    gene2og[k] = og\n",
    "\n",
    "print(case_new_og,case_single_og,case_multi_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 134905 0\n"
     ]
    }
   ],
   "source": [
    "case_new_og = 0\n",
    "case_single_og = 0\n",
    "case_multi_og = 0\n",
    "\n",
    "with open(tilapia_biomart) as biomart:\n",
    "    biomart.readline()\n",
    "    for line in biomart:\n",
    "        line = line.strip().split('\\t')\n",
    "        line = [item for item in line if item != '']\n",
    "        belong_group = set()  # if a gene is already in a OG, add this OG the this set\n",
    "        for id in line:\n",
    "            if id in gene2og:\n",
    "                belong_group.add(gene2og[id])\n",
    "        \n",
    "        if len(belong_group) == 0:  # all geneID are new, we create an OG and add all gene to this OG\n",
    "            case_new_og += 1\n",
    "            og = new_group\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "            new_group += 1\n",
    "\n",
    "        elif len(belong_group) == 1:  # if one or multiple geneID come from an already assign OG, assign other ID to this one\n",
    "            case_single_og += 1\n",
    "            og = list(belong_group)[0]\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "        else:  # if two or more geneID are already assigned to different OG, we arbitrary assign all to one of them and reassign all gene in other OG to the select one\n",
    "            case_multi_og += 1\n",
    "            og = list(belong_group)[0]\n",
    "            belong_group.remove(og)\n",
    "            for id in line:\n",
    "                gene2og[id] = og\n",
    "            for k,v in gene2og.items():\n",
    "                if v in belong_group:\n",
    "                    gene2og[k] = og\n",
    "\n",
    "print(case_new_og,case_single_og,case_multi_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_gene(similarity_path : str, proportion : float) -> set[str]:\n",
    "    data : pd.DataFrame = pd.read_csv(similarity_path, sep='\\t')\n",
    "    threshold : float = np.nanpercentile(data['BP_similarity_longest'], proportion)\n",
    "    return set(data[data['BP_similarity_longest'] <= threshold]['gene_id'].apply(lambda x: x.split(':')[1]))\n",
    "\n",
    "def get_available_gene(similarity_path : str, proportion : float, all_available_gene : set[str]) -> set[str]:\n",
    "    candidate_gene : set[str] = get_candidate_gene(similarity_path, proportion)\n",
    "    return set.intersection(candidate_gene, all_available_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "og2gene : dict[int, str] = dict()\n",
    "for gene, og in gene2og.items():\n",
    "    if og in og2gene:\n",
    "        og2gene[og].add(gene)\n",
    "    else:\n",
    "        og2gene[og] = {gene}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'human.table.similarity.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m human_set \u001b[38;5;241m=\u001b[39m \u001b[43mget_available_gene\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhuman_similarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgene2og\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m, in \u001b[0;36mget_available_gene\u001b[0;34m(similarity_path, proportion, all_available_gene)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_available_gene\u001b[39m(similarity_path : \u001b[38;5;28mstr\u001b[39m, proportion : \u001b[38;5;28mfloat\u001b[39m, all_available_gene : \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m     candidate_gene : \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mget_candidate_gene\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarity_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproportion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39mintersection(candidate_gene, all_available_gene)\n",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m, in \u001b[0;36mget_candidate_gene\u001b[0;34m(similarity_path, proportion)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_candidate_gene\u001b[39m(similarity_path : \u001b[38;5;28mstr\u001b[39m, proportion : \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     data : pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarity_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     threshold : \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanpercentile(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBP_similarity_longest\u001b[39m\u001b[38;5;124m'\u001b[39m], proportion)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBP_similarity_longest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgene_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m/nfs/users/rg/pgerenton/.jupyterkernel/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nfs/users/rg/pgerenton/.jupyterkernel/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/nfs/users/rg/pgerenton/.jupyterkernel/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nfs/users/rg/pgerenton/.jupyterkernel/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/nfs/users/rg/pgerenton/.jupyterkernel/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'human.table.similarity.txt'"
     ]
    }
   ],
   "source": [
    "human_set = get_available_gene(human_similarity, 3, gene2og.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterkernel",
   "language": "python",
   "name": "jupyterkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
